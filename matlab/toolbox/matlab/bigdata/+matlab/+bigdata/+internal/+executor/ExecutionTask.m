%ExecutionTask
% A description of one piece of execution across multiple partitions that
% generates a single partitioned output. This execution can take as input,
% zero or more partitioned arrays generated by previous ExecutionTask
% instances.
%
% Each task includes the following pieces of information:
%  - A list of tasks that act as the input to this task.
%  - A factory to construct one data processor for each execution partition.
%  - How the execution of the task should be partitioned.
%  - How the output of the task will be partitioned.
%  - What kind of communication is needed to send the output to the correct
%  location.
%  - What form of caching is desired for the output.
%
% To construct an Execution task, use one of the following factory methods:
%  createSimpleTask - Create a task with non-communicating output.
%  createAllToOneTask - Create a task where all output is sent to a single partition.
%  createAnyToAnyTask -Create a task where any output could be sent to any partition.
%  createBroadcastTask -Create a task where all output will be sent all partitions.
%

%   Copyright 2015-2019 The MathWorks, Inc.

classdef (Sealed) ExecutionTask < handle
    properties (SetAccess = immutable)
        % A numeric ID for this task.
        %
        % This is not guaranteed to be unique across multiple MATLAB
        % sessions.
        Id
        
        % An ordered list of IDs representing the inputs to this
        % execution task.
        %
        % For the Nth input ID in this list, all output from the
        % corresponding ExecutionTask that is intended for partition P will
        % be passed to the data processor of execution partition P. It will
        % be passed in chunks as the Nth varargin input of the
        % DataProcessor/process method.
        InputIds
        
        % A string representing the type of output with respect to
        % communication. This can be one of:
        % 'Simple' - All output of each DataProcessor will be sent to the
        % same partition index as execution partition index.
        % 'AllToOne' - All output of all DataProcessors will be sent to
        % output partition 1.
        % 'AnyToAny' - Any output of each DataProcessor can go to any
        % output partition. This allows any form of communication pattern.
        % 'Broadcast' - All output of each DataProcessor will be sent to
        % all output partitions.
        OutputCommunicationType
        
        % Number of output variables that will be emitted from this task.
        NumOutputs;
        
        % The level of caching requested by the algorithm that generated
        % this execution task. This can be one of:
        %  'None' - No caching is requested.
        %  'All'  - Cache requested to all forms of available storage.
        CacheLevel;
        
        % A key that represents any cached entries resulting from this
        % execution task. These entries can be reused by holding onto the
        % key and providing it to future instances of ExecutionTask.
        CacheEntryKey;
        
        % A logical scalar that indicates whether this task requires a full
        % pass of the underlying data before the output can be used by
        % downstream tasks.
        %
        % This can be false only if it is safe to evaluate this task in the
        % same pass of the underlying data as all downstream tasks who
        % depend on the output of this task.
        IsPassBoundary;
        
        % The strategy for partitioning the execution of this task.
        %
        % A data processor will be instantiated for each execution
        % partition.
        %
        % Note, this must be compatible with the partitioning of the inputs
        % to this task. This must match the output partition strategy for
        % every non-broadcast input task.
        ExecutionPartitionStrategy
        
        % Does this task process a large amount of data?
        %
        % This ensures that progress reporting is correct. This will be
        % true for any task that runs over a datastore, or something that
        % can be equally as large.
        IsExecutionLarge (1,1) logical = false;
        
        % The strategy for partitioning the output of this task.
        %
        % This specifies how many partitions exist in the partitioned array
        % output of this task. In most cases, this is fixed by the
        % combination of the output communication type and execution
        % partition strategy.
        OutputPartitionStrategy
        
        % Does this task emit a large amount of data?
        %
        % This ensures that progress reporting is correct. This will be
        % true for any task that runs over a datastore, or something that
        % can be equally as large.
        IsOutputLarge (1,1) logical = false;
        
        % For PadWithEmptyPartition communication only. The index into the
        % Strategies property of an output ConcatenatedPartitionStrategy
        % that corresponds with the execution partition strategy.
        OutputSubIndex (1,1) double
        
        % A factory for DataProcessor instances. This is a function handle
        % or object that obeys the feval contract, that will be called with
        % the syntax:
        %   function dataProcessor = myFactory(partition)
        %
        % Where partition is an instance of DatastorePartition if the
        % execution partition strategy is based on a datastore or
        % SimplePartition otherwise.
        DataProcessorFactory
    end
    
    properties (Access = private, Constant)
        % The means by which this class receives unique IDs.
        IdFactory = matlab.bigdata.internal.util.UniqueIdFactory('ExecutionTask');
    end
    
    methods (Static)
        %CREATESIMPLETASK Create a task with non-communicating output.
        %
        % All output from each data processor associated with this task
        % will be sent to the same output partition index as execution
        % partition index.
        %
        % Syntax:
        %  obj = ExecutionTask.createSimpleTask(inputTasks,dataProcessorFactory,numOutputs,name1,value1,...);
        %
        % Required Inputs:
        %  - inputTasks: An ordered list of ExecutionTask instances that
        %  represent the inputs to this task. This is allowed to be empty.
        %  - dataProcessorFactory: A data processor factory that will be
        %  used to create the underlying data processors for this task.
        %  - numOutputs: The number of outputs from the data processor.
        %
        % Parameter Inputs:
        %  - 'ExecutionPartitionStrategy': The strategy for how to
        %  partition execution. If this is an integer, a fixed partitioning
        %  will be used. If this is a datastore, partitioning will be based
        %  on the datastore. If this is not set, the execution environment
        %  has full control over the partitioning.
        %  - 'CacheLevel': The allowed ways to do caching. This is either
        %  'None' for no caching, or 'All' for caching to disk and memory.
        %  - 'IsPassBoundary': A logical scalar that indicates whether this
        %  task requires a full pass of the underlying data before the
        %  output can be used by downstream tasks. This can be false only
        %  if it is safe to evaluate this task in the same pass of the
        %  underlying data as all downstream tasks who depend on the output
        %  of this task.
        %
        % Outputs:
        %  - obj: The constructed ExecutionTask instance.
        %
        function obj = createSimpleTask(inputTasks, dataProcessorFactory, numOutputs, varargin)
            import matlab.bigdata.internal.executor.ExecutionTask;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            inputStruct = iParseFactoryInputs(inputTasks, dataProcessorFactory, numOutputs, varargin{:});
            
            if isempty(inputStruct.OutputPartitionStrategy)
                inputStruct.OutputPartitionStrategy = inputStruct.ExecutionPartitionStrategy;
            else
                assert (isequal(inputStruct.OutputPartitionStrategy, inputStruct.ExecutionPartitionStrategy));
            end
            if isempty(inputStruct.IsOutputLarge)
                inputStruct.IsOutputLarge = inputStruct.IsExecutionLarge;
            end
            obj = ExecutionTask([], OutputCommunicationType.Simple, inputStruct);
        end
        
        %CREATEALLTOONETASK Create a task where all output is sent to a single partition.
        %
        % All output from each data processor associated with this task
        % will be sent to the output partition 1.
        %
        % Syntax:
        %  obj = ExecutionTask.createAllToOneTask(inputTasks,dataProcessorFactory,numOutputs,name1,value1,...);
        %
        % Required Inputs:
        %  - inputTasks: An ordered list of ExecutionTask instances that
        %  represent the inputs to this task. This is allowed to be empty.
        %  - dataProcessorFactory: A data processor factory that will be
        %  used to create the underlying data processors for this task.
        %  - numOutputs: The number of outputs from the data processor.
        %
        % Parameter Inputs:
        %  - 'ExecutionPartitionStrategy': The strategy for how to
        %  partition execution. If this is an integer, a fixed partitioning
        %  will be used. If this is a datastore, partitioning will be based
        %  on the datastore. If this is not set, the execution environment
        %  has full control over the partitioning.
        %  - 'IsPassBoundary': A logical scalar that indicates whether this
        %  task requires a full pass of the underlying data before the
        %  output can be used by downstream tasks. This can be false only
        %  if it is safe to evaluate this task in the same pass of the
        %  underlying data as all downstream tasks who depend on the output
        %  of this task.
        %
        % Outputs:
        %  - obj: The constructed ExecutionTask instance.
        %
        function obj = createAllToOneTask(inputTasks, dataProcessorFactory, numOutputs, varargin)
            import matlab.bigdata.internal.executor.ExecutionTask;
            import matlab.bigdata.internal.executor.FixedNumPartitionStrategy;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            inputStruct = iParseFactoryInputs(inputTasks, dataProcessorFactory, numOutputs, varargin{:});
            
            if isempty(inputStruct.OutputPartitionStrategy)
                inputStruct.OutputPartitionStrategy = FixedNumPartitionStrategy(1);
            else
                assert (isequal(inputStruct.OutputPartitionStrategy, FixedNumPartitionStrategy(1)));
            end
            if isempty(inputStruct.IsOutputLarge)
                inputStruct.IsOutputLarge = false;
            end
            obj = ExecutionTask([], OutputCommunicationType.AllToOne, inputStruct);
        end
        
        %CREATEANYTOANYTASK Create a task where any output could be sent to any partition.
        %
        % Data processor associated with this task are expected to return
        % partition indices alongside the data output. These partition
        % indices will be used to send the corresponding data output to the
        % target partitions.
        %
        % Syntax:
        %  obj = ExecutionTask.createAnyToAnyTask(inputTasks,dataProcessorFactory,numOutputs,name1,value1,...);
        %
        % Required Inputs:
        %  - inputTasks: An ordered list of ExecutionTask instances that
        %  represent the inputs to this task. This is allowed to be empty.
        %  - dataProcessorFactory: A data processor factory that will be
        %  used to create the underlying data processors for this task.
        %  - numOutputs: The number of outputs from the data processor.
        %
        % Parameter Inputs:
        %  - 'ExecutionPartitionStrategy': The strategy for how to
        %  partition execution. If this is an integer, a fixed partitioning
        %  will be used. If this is a datastore, partitioning will be based
        %  on the datastore. If this is not set, the execution environment
        %  has full control over the partitioning.
        %  - 'OutputPartitionStrategy': The strategy for how the output
        %  will be partitioned. If this is an integer, a fixed partitioning
        %  will be used. If this is a datastore, partitioning will be based
        %  on the datastore. If this is not set, the execution environment
        %  has full control over the partitioning.
        %  - 'IsPassBoundary': A logical scalar that indicates whether this
        %  task requires a full pass of the underlying data before the
        %  output can be used by downstream tasks. This can be false only
        %  if it is safe to evaluate this task in the same pass of the
        %  underlying data as all downstream tasks who depend on the output
        %  of this task.
        %
        % Outputs:
        %  - obj: The constructed ExecutionTask instance.
        %
        function obj = createAnyToAnyTask(inputTasks, dataProcessorFactory, numOutputs, varargin)
            import matlab.bigdata.internal.executor.ArbitraryPartitionStrategy;
            import matlab.bigdata.internal.executor.ExecutionTask;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            inputStruct = iParseFactoryInputs(inputTasks, dataProcessorFactory, numOutputs, varargin{:});
            
            if isempty(inputStruct.OutputPartitionStrategy)
                inputStruct.OutputPartitionStrategy = ArbitraryPartitionStrategy();
            end
            if isempty(inputStruct.IsOutputLarge)
                inputStruct.IsOutputLarge = inputStruct.IsExecutionLarge;
            end
            obj = ExecutionTask([], OutputCommunicationType.AnyToAny, inputStruct);
        end
        
        %createPadWithEmptyPartitionsTask Create a task where the
        %partitioned array is padded with empty partitions. The empty
        %partitions can be prepended, appended or both.
        %
        % Syntax:
        %  obj = ExecutionTask.createPadWithEmptyPartitionsTask(inputTasks,dataProcessorFactory,numOutputs,...
        %      'OutputPartitionStrategy',outputPartitionStrategy,...
        %      'OutputSubIndex',outputSubIndex);
        %
        % Required Inputs:
        %  - inputTasks: An ordered list of ExecutionTask instances that
        %  represent the inputs to this task. This is allowed to be empty.
        %  - dataProcessorFactory: A data processor factory that will be
        %  used to create the underlying data processors for this task.
        %  - numOutputs: The number of outputs from the data processor.
        %  This must be 1.
        %  - outputPartitionStrategy: The expected OutputPartitionStrategy,
        %  this must be of type ConcatenatedPartitionStrategy.
        %  - outputSubIndex: Index into outputPartitionStrategy that
        %  corresponds with the input partition strategy.
        function obj = createPadWithEmptyPartitionsTask(inputTasks, dataProcessorFactory, numOutputs, varargin)
            assert(numOutputs == 1, ...
                'Assertion Failed: PadWithEmptyPartitions only supports a single output');
            import matlab.bigdata.internal.executor.ExecutionTask;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            
            inputStruct = iParseFactoryInputs(inputTasks, dataProcessorFactory, numOutputs, varargin{:});
            assert(~isempty(inputStruct.OutputPartitionStrategy), ...
                'Assertion failed: OutputPartitionStrategy is a required parameter.');
            if isempty(inputStruct.IsOutputLarge)
                inputStruct.IsOutputLarge = inputStruct.IsExecutionLarge;
            end
            
            obj = ExecutionTask([], OutputCommunicationType.PadWithEmptyPartitions, inputStruct);
        end
        
        %CREATEBROADCASTTASK Create a task where all output will be sent all partitions.
        %
        % All output from each data processor associated with this task
        % will be sent to all partitions.
        %
        % Syntax:
        %  obj = ExecutionTask.createBroadcastTask(inputTasks,dataProcessorFactory,numOutputs,name1,value1,...);
        %
        % Required Inputs:
        %  - inputTasks: An ordered list of ExecutionTask instances that
        %  represent the inputs to this task. This is allowed to be empty.
        %  - dataProcessorFactory: A data processor factory that will be
        %  used to create the underlying data processors for this task.
        %  - numOutputs: The number of outputs from the data processor.
        %
        % Parameter Inputs:
        %  - 'ExecutionPartitionStrategy': The strategy for how to
        %  partition execution. If this is an integer, a fixed partitioning
        %  will be used. If this is a datastore, partitioning will be based
        %  on the datastore. If this is not set, the execution environment
        %  has full control over the partitioning.
        %  - 'IsPassBoundary': A logical scalar that indicates whether this
        %  task requires a full pass of the underlying data before the
        %  output can be used by downstream tasks. This can be false only
        %  if it is safe to evaluate this task in the same pass of the
        %  underlying data as all downstream tasks who depend on the output
        %  of this task.
        %
        % Outputs:
        %  - obj: The constructed ExecutionTask instance.
        %
        function obj = createBroadcastTask(inputTasks, dataProcessorFactory, numOutputs, varargin)
            import matlab.bigdata.internal.executor.BroadcastPartitionStrategy;
            import matlab.bigdata.internal.executor.ExecutionTask;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            inputStruct = iParseFactoryInputs(inputTasks, dataProcessorFactory,numOutputs, varargin{:});
            
            if isempty(inputStruct.OutputPartitionStrategy)
                inputStruct.OutputPartitionStrategy = BroadcastPartitionStrategy();
            else
                assert (isequal(inputStruct.OutputPartitionStrategy, BroadcastPartitionStrategy()));
            end
            if isempty(inputStruct.IsOutputLarge)
                inputStruct.IsOutputLarge = false;
            end
            obj = ExecutionTask([], OutputCommunicationType.Broadcast, inputStruct);
        end
    end
    
    methods
        %CREATEDATAPROCESSOR Create a data processor that will perform the
        %underlying execution this task represents for the given partition
        %index.
        %
        % Syntax:
        %  partition = obj.createDataProcessor(partitionIndex) creates a
        %  datastore based on the execution partitioning provided by
        %  default by the ExecutionPartitionStrategy.
        %
        %  partition = obj.createDataProcessor(partitionIndex, numPartitions) creates a
        %  datastore based on numPartitions. The numPartitions input must
        %  be between MinNumPartitions and MaxNumPartitions of the
        %  execution partition strategy.
        %
        %  partition = obj.createDataProcessor(partitionIndex, numPartitions, hadoopSplit)
        %  creates a datastore based on the provided datastore Hadoop split.
        %  The partitionIndex must match corresponding partition index of
        %  the Hadoop split. This argument is only supported if
        %  IsDatastorePartitioning is true on the ExecutionPartitionStrategy.
        %
        % Inputs:
        %  - obj: The ExecutionTask instance object.
        %  - partitionIndex: The partition index to use for the data
        %  processor. This must be a scalar integer in the range
        %  1:NumPartitions.
        %  - numPartitions: The total number of partitions. This is an
        %  override for the datastore based strategy.
        %  - hadoopSplit: A Hadoop split generated by HDFS. This precisely
        %  defines a partition for HDFS based data.
        %
        % Outputs:
        %  - dataProcessor: The constructed DataProcessor instance.
        %
        function dataProcessor = createDataProcessor(obj, partitionIndex, varargin)
            partition = obj.ExecutionPartitionStrategy.createPartition(partitionIndex, varargin{:});
            dataProcessor = feval(obj.DataProcessorFactory, partition);
        end
        
        %COPYWITHNEWID Return a copy of the ExecutionTask instance but with
        % a new ID. This is useful if the task is being duplicated in a
        % single task graph.
        function out = copyWithNewId(obj, id)
            if nargin < 2
                % Pass in [] as the ID in order to auto-generate a new one.
                id = [];
            end
            [~, outputCommunicationType, inputStruct] = obj.getBuildArgs();
            out = matlab.bigdata.internal.executor.ExecutionTask(...
                id, outputCommunicationType, inputStruct);
        end
        
        %COPYWITHREPLACEDPROCESSORFACTORY Return a copy of an ExecutionTask
        % instance with a replaced processor factory.
        %
        % Syntax:
        %  newTask = copyWithReplacedProcessorFactory(task, newDataProcessorFactory)
        %  returns a copy of task where the task data processor has been
        %  replaced with newDataProcessorFactory.
        %
        function out = copyWithReplacedProcessorFactory(obj, newDataProcessorFactory)
            [id, outputCommunicationType, inputStruct] = obj.getBuildArgs();
            inputStruct.DataProcessorFactory = newDataProcessorFactory;
            out = matlab.bigdata.internal.executor.ExecutionTask(...
                id, outputCommunicationType, inputStruct);
        end
        
        %COPYWITHREPLACEDINPUTS Return a copy of an ExecutionTask instance
        % for which the input tasks have been replaced by new ones.
        %
        % Syntax:
        %  newTask = copyWithReplacedInputs(task, newInputTasks, newDataProcessorFactory)
        %  returns a copy of task but with new input IDs and data process
        %  factory set to newInputIds and newDataProcessorFactory
        %  respectively.
        %
        function out = copyWithReplacedInputs(obj, newInputTasks, newDataProcessorFactory)
            import matlab.bigdata.internal.executor.ExecutionTask;
            
            if isempty(newInputTasks)
                newInputTasks = ExecutionTask.empty(0, 1);
            else
                assert (isa(newInputTasks, 'matlab.bigdata.internal.executor.ExecutionTask'));
            end
            [id, outputCommunicationType, inputStruct] = obj.getBuildArgs();
            inputStruct.InputTaskIds = {newInputTasks.Id};
            if nargin >= 3
                inputStruct.DataProcessorFactory = newDataProcessorFactory;
            end
            
            out = ExecutionTask(id, outputCommunicationType, inputStruct);
        end

        %COPYWITHREPLACEDEXECUTIONSTRATEGY Return a copy of an ExecutionTask
        % instance where execution strategy has been replaced with a new
        % one. This also requires a new data processor factory as the two
        % are typically coupled.
        %
        % Syntax:
        %  newTask = copyWithReplacedExecutionStrategy(task, newExecutionPartitionStrategy, newProcessorFactory)
        %
        function out = copyWithReplacedExecutionStrategy(obj, newExecutionPartitionStrategy, newProcessorFactory)
            import matlab.bigdata.internal.executor.ExecutionTask;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            
            [id, outputCommunicationType, inputStruct] = obj.getBuildArgs();
            inputStruct.ExecutionPartitionStrategy = newExecutionPartitionStrategy;
            if outputCommunicationType == OutputCommunicationType.Simple %#ok<PROPLC>
                inputStruct.OutputPartitionStrategy = newExecutionPartitionStrategy;
            end
            inputStruct.DataProcessorFactory = newProcessorFactory;
            out = ExecutionTask(id, outputCommunicationType, inputStruct);
        end
        
        %COPYWITHREPLACEDCOMMUNICATION Return a copy of an ExecutionTask
        % instance where communication has been replaced with a new
        % one. This also requires a new data processor and a new output
        % partition strategy as the three are typically coupled.
        %
        % Syntax:
        %  newTask = copyWithReplacedCommunication(task, newCommType, newOutputPartitionStrategy, newProcessorFactory)
        %
        function out = copyWithReplacedCommunication(obj, newCommType, newOutputPartitionStrategy, newProcessorFactory)
            import matlab.bigdata.internal.executor.ExecutionTask;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            
            [id, ~, inputStruct] = obj.getBuildArgs();
            inputStruct.OutputPartitionStrategy = newOutputPartitionStrategy;
            if nargin >= 4
                inputStruct.DataProcessorFactory = newProcessorFactory;
            end
            out = ExecutionTask(id, newCommType, inputStruct);
        end
        
        %COPYWITHBROADCASTOUTPUT Return a copy of an ExecutionTask instance
        % where the communication action has been replaced with a broadcast
        % communication.
        %
        % Syntax:
        %  newTask = copyWithBroadcastOutput(task)
        %
        % This exists to allow the Spark back-end to perform the final
        % reduction of an aggregate in the client process instead of a
        % worker process. This function exists because the instruction to
        % reduce using a worker is encoded into the execution task graph.
        function out = copyWithBroadcastOutput(obj)
            import matlab.bigdata.internal.executor.BroadcastPartitionStrategy;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            
            out = obj.copyWithReplacedCommunication(OutputCommunicationType.Broadcast, BroadcastPartitionStrategy()); %#ok<PROP>
        end
        
        %COPYWITHBROADCASTEXECUTION Return a copy of an ExecutionTask instance
        % where the execution partition strategy has been replaced by the
        % broadcast partition strategy.
        %
        % Syntax:
        %  newTask = copyWithBroadcastExecution(task)
        %
        % This exists to allow the Spark back-end to perform the final
        % reduction of an aggregate in the client process instead of a
        % worker process. This function exists because the instruction to
        % reduce using a worker is encoded into the execution task graph.
        function out = copyWithBroadcastExecution(obj)
            import matlab.bigdata.internal.executor.BroadcastPartitionStrategy;
            import matlab.bigdata.internal.executor.ExecutionTask;
            import matlab.bigdata.internal.executor.OutputCommunicationType;
            
            outputPartitionStrategy = obj.OutputPartitionStrategy;
            if obj.OutputCommunicationType == OutputCommunicationType.Simple %#ok<PROP>
                outputPartitionStrategy = BroadcastPartitionStrategy();
            end
            
            [id, outputCommunicationType, inputStruct] = obj.getBuildArgs();
            inputStruct.ExecutionPartitionStrategy = BroadcastPartitionStrategy();
            inputStruct.OutputPartitionStrategy = outputPartitionStrategy;
            
            out = ExecutionTask(id, outputCommunicationType, inputStruct);
        end
    end
    
    methods (Access = private)
        % Private constructor for factory methods.
        function obj = ExecutionTask(id, outputCommunicationType, inputStruct)
            if isempty(id)
                id = obj.IdFactory.nextId();
            end
            obj.Id = id;
            obj.InputIds = inputStruct.InputTaskIds;
            obj.OutputCommunicationType = outputCommunicationType;
            obj.CacheLevel = inputStruct.CacheLevel;
            obj.IsPassBoundary = inputStruct.IsPassBoundary;
            obj.ExecutionPartitionStrategy = inputStruct.ExecutionPartitionStrategy;
            obj.OutputPartitionStrategy = inputStruct.OutputPartitionStrategy;
            obj.DataProcessorFactory = inputStruct.DataProcessorFactory;
            obj.NumOutputs = inputStruct.NumOutputs;
            obj.CacheEntryKey = inputStruct.CacheEntryKey;
            obj.IsExecutionLarge = inputStruct.IsExecutionLarge;
            obj.IsOutputLarge = inputStruct.IsOutputLarge;
            obj.OutputSubIndex = inputStruct.OutputSubIndex;
        end
        
        function [id, communicationType, inputStruct] = getBuildArgs(obj)
            % Get the original build args used to construct this object.
            id = obj.Id;
            communicationType = obj.OutputCommunicationType;
            inputStruct = struct(...
                'InputTaskIds', {obj.InputIds}, ...
                'CacheLevel', {obj.CacheLevel}, ...
                'IsPassBoundary', {obj.IsPassBoundary}, ...
                'ExecutionPartitionStrategy', {obj.ExecutionPartitionStrategy}, ...
                'OutputPartitionStrategy', {obj.OutputPartitionStrategy}, ...
                'DataProcessorFactory', {obj.DataProcessorFactory}, ...
                'NumOutputs', {obj.NumOutputs},...
                'CacheEntryKey', {obj.CacheEntryKey}, ...
                'IsExecutionLarge', {obj.IsExecutionLarge}, ...
                'IsOutputLarge', {obj.IsOutputLarge}, ...
                'OutputSubIndex', {obj.OutputSubIndex});
        end
    end
end

% Helper function that deals with the common input parsing shared by all
% factory methods.
function inputStruct = iParseFactoryInputs(varargin)
import matlab.bigdata.internal.executor.CacheEntryKey;
import matlab.bigdata.internal.executor.ExecutionTask;
p = inputParser;
p.addRequired('InputTasks');
p.addRequired('DataProcessorFactory');
p.addRequired('NumOutputs');
p.addParameter('CacheLevel', 'None');
p.addParameter('CacheEntryKey', []);
p.addParameter('IsPassBoundary', false);
p.addParameter('ExecutionPartitionStrategy', []);
p.addParameter('OutputPartitionStrategy', []);
p.addParameter('IsExecutionLarge', [], @(x) isscalar(x) && islogical(x));
p.addParameter('IsOutputLarge', [], @(x) isscalar(x) && islogical(x));
p.addParameter('OutputSubIndex', NaN);
p.parse(varargin{:});
inputStruct = p.Results;

% InputTasks
if isempty(inputStruct.InputTasks)
    inputStruct.InputTasks = ExecutionTask.empty(1, 0);
end
assert (isa(inputStruct.InputTasks,'matlab.bigdata.internal.executor.ExecutionTask'), ...
    'InputTasks must be a list of ExecutionTask instances.');
inputStruct.InputTaskIds = {inputStruct.InputTasks.Id};

% DataProcessor
assert (~isempty(inputStruct.DataProcessorFactory), 'DataProcessorFactory cannot be empty.');

% DataProcessor
validateattributes(inputStruct.NumOutputs, {'double'}, ...
    {'scalar', 'integer', 'positive'}, 'ExecutionTask', 'NumOutputs');

% CacheLevel
assert (any(strcmp(inputStruct.CacheLevel, {'None', 'All'})), 'CacheLevel must be either ''None'' or ''All''.');

% CacheEntryKey
if isempty(inputStruct.CacheEntryKey)
    inputStruct.CacheEntryKey = CacheEntryKey();
else
    assert (isscalar(inputStruct.CacheEntryKey) ...
        && isa(inputStruct.CacheEntryKey, 'matlab.bigdata.internal.executor.CacheEntryKey'), ...
        'Assertion failed: CacheEntryKey input must be a scalar CacheEntryKey object.');
end

% IsPassBoundary
assert (islogical(inputStruct.IsPassBoundary) && isscalar(inputStruct.IsPassBoundary), ...
    'Assertion failed: IsPassBoundary must be a scalar logical.');

% ExecutionPartitionStrategy
if isempty(inputStruct.ExecutionPartitionStrategy)
    inputStruct.ExecutionPartitionStrategy = iDiscoverInputPartitionStrategy(inputStruct.InputTasks);
else
    assert(isa(inputStruct.ExecutionPartitionStrategy, 'matlab.bigdata.internal.executor.PartitionStrategy'));
end

% OutputPartitionStrategy
if ~isempty(inputStruct.OutputPartitionStrategy)
    assert(isa(inputStruct.ExecutionPartitionStrategy, 'matlab.bigdata.internal.executor.PartitionStrategy'));
end

% IsExecutionLarge
if isempty(inputStruct.IsExecutionLarge)
    inputStruct.IsExecutionLarge = inputStruct.ExecutionPartitionStrategy.IsDatastorePartitioning ...
        || any([inputStruct.InputTasks.IsOutputLarge]);
end

end

% Use the input tasks to determine the input partition strategy.
function strategy = iDiscoverInputPartitionStrategy(inputTasks)
import matlab.bigdata.internal.executor.PartitionStrategy;
strategy = PartitionStrategy.align(inputTasks.OutputPartitionStrategy);
end
