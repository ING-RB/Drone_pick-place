<?xml version="1.0" encoding="UTF-8"?>
<!--Copyright 2024 The MathWorks, Inc.-->

<rsccat xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.0" locale="ja_JP" product="parallel" xsi:noNamespaceSchemaLocation="../../resources/schema/msgcat.xsd">
  <message>
    <entry key="CannotAccessOutputFiles" context="error">Unable to access output files written to the folder ''{0}''. Folder location must be accessible to both the client MATLAB and the cluster machines.</entry>
    <entry key="CannotCreateOutputFolder" context="error">Failed to create the output folder ''{0}''.</entry>
    <entry key="HadoopClusterObjectNotValid">Hadoop クラスター オブジェクトが有効ではありません。これは、MAT ファイルからクラスター オブジェクトまたは mapreducer オブジェクトを読み込んだことが原因です。現在これはサポートされていません。</entry>
    <entry key="HadoopDefaultJobName">MATLAB 並列計算ジョブ</entry>
    <entry key="HadoopJobFailure">HADOOP ジョブを完了できませんでした。</entry>
    <entry key="HadoopJobOtherFailure">HADOOP ジョブを完了できませんでした。詳細は、ジョブ {0} の HADOOP ログ ファイルを確認してください。</entry>
    <entry key="HadoopJobSubmitExecutionFailure" context="error">The HADOOP job failed to submit. Check for issues with the HADOOP configuration.</entry>
    <entry key="HadoopJobSubmitFailure">HADOOP ジョブを投入できませんでした。これは次のエラーが原因です:\n\n{0}</entry>
    <entry key="HadoopMatlabFailure">MATLAB コードの実行中にエラーが発生しました。\n\n{0}</entry>
    <entry key="HadoopOutputNotFound">HADOOP ジョブは正常に完了しましたが、クライアントの MATLAB で場所 ''{0}'' に出力ファイルが見つかりません。''OutputFolder'' プロパティが、クライアント マシンと Hadoop クラスターの両方で共有される場所に設定されていることを確認してください。たとえば、HDFS 内のフォルダーや、共有ネットワーク ドライブ上のフォルダーなどです。</entry>
    <entry key="HadoopRequiresOutputFolder" context="error">To use Mapreduce with HADOOP, the ''OutputFolder'' parameter must specify a path to a folder that does not already exist.</entry>
    <entry key="HadoopSparkEvaluationFailure" context="error">Failed to launch MATLAB Workers on the cluster.</entry>
    <entry key="HadoopSparkJobSubmitExitEarly">Spark 投入処理が、次の出力を伴い早期終了しました。\n\n{0}</entry>
    <entry key="HadoopSparkJobSubmitExitEarlyNoOutput" context="error">Spark submit process exited early with no output.</entry>
    <entry key="HadoopSparkJobSubmitFailure" context="error">Failed to launch a Spark job on the cluster. Check that the installation of Spark at ''{0}'' is valid and configured correctly.</entry>
    <entry key="HadoopSparkUnsupportedVersion" context="error">HADOOP version not supported. Evaluating tall array expressions is only supported on a HADOOP cluster of version 2 or later.</entry>
    <entry key="HadoopTaskCouldNotFindMatlab" context="error">Unable to find correct installation of MATLAB Parallel Server for attempt {0} of ''{1}'' task {2}. ''ClusterMatlabRoot'' property on the mapreducer cluster object must be set to the MATLAB Parallel Server installation on the cluster.</entry>
    <entry key="HadoopTaskInvalidHome" context="error">Unable to start MATLAB for attempt {0} of ''{1}'' task {2} because the HOME environment variable was set to ''{3}'', which either does not exist or is not writable. HOME environment variable must be a valid local path on the cluster. See the documentation on {4}Configure a HADOOP cluster{5}.</entry>
    <entry key="HadoopTaskOtherFailure" context="error">Unable to start MATLAB for attempt {0} of ''{1}'' task {2} because of an invalid license for MATLAB Parallel Server or a corruption in the MATLAB Parallel Server installation on the cluster. Check the HADOOP log files for job {3} for more information.</entry>
    <entry key="HadoopTaskVersionMismatch" context="error">Unable to start MATLAB for attempt {0} of ''{1}'' task {2}. HADOOP job was submitted from a client running version {3} of Parallel Computing Toolbox, to a cluster running version {4} of MATLAB Parallel Server. Client and server must run parallel computing products of the same version.</entry>
    <entry key="HadoopTaskWindowsUnsupported" context="error">Unable to start MATLAB for attempt {0} of ''{1}'' task {2}. Running mapreduce from MATLAB using a Hadoop cluster running on Windows is not supported.</entry>
    <entry key="InconsistentKeyType">キーの型の間に一貫性がありません。キーはすべて同じ型のスカラー数値か、すべて文字ベクトルでなければなりません。</entry>
    <entry key="InternalExecutionError">mapreduce の実行中に、mapreduce フレームワークで内部エラーが検出されました。</entry>
    <entry key="InvalidHadoopInstallFolder">''{0}'' を有効な HADOOP インストール フォルダーとして認識できません。これが HADOOP インストールのルート フォルダーであることを確認してください。</entry>
    <entry key="InvalidHadoopOutputFolder">出力フォルダー ''{0}'' を HADOOP タスクによって作成できませんでした。HADOOP がこの場所にアクセスでき、HADOOP にこのフォルダーを作成するアクセス許可があることを確認してください。</entry>
    <entry key="InvalidKeyType">キーに無効な型 ''{0}'' が含まれています。キーはすべて同じ型のスカラー数値か、すべて文字ベクトルでなければなりません。</entry>
    <entry key="InvalidMapFunction">マッパー関数ハンドルが無効です。これは、マッパー関数を含むファイルがワーカーで使用できないことを示しています。プールまたはクラスターの 'AttachedFiles' プロパティを設定して、必要なファイルを指定してください。</entry>
    <entry key="InvalidParameterName">無効なパラメーター名 ''{0}''。mapreduce の有効なパラメーターは 'OutputFolder'、'OutputType'、'Display' です。</entry>
    <entry key="InvalidReduceFunction">リデューサーの関数ハンドルが無効です。これは、マッパー関数を含むファイルがワーカーで使用できないことを示しています。プールまたはクラスターの 'AttachedFiles' プロパティを設定して、必要なファイルを指定してください。</entry>
    <entry key="InvalidSparkInstallFolder">''{0}'' を有効な Spark インストール フォルダーとして認識できません。これが Spark インストールのルート フォルダーであることを確認してください。 </entry>
    <entry key="InvalidURL">URL ''{0}'' が無効です。場所を URL で指定する場合、''scheme:/path/to/location'' または ''scheme://hostname:port/path/to/location'' の形式でなければなりません。</entry>
    <entry key="MismatchedKeyType">mapper 関数に対する 2 つの異なる呼び出しから、一致しないキーの型が返されました。その型は ''{0}'' と ''{1}'' です。</entry>
    <entry key="MismatchedValueType">mapper 関数に対する 2 つの異なる呼び出しから、一致しない値の型が返されました。その型は ''{0}'' と ''{1}'' です。</entry>
    <entry key="MpiShufflerAlreadyRunning">シャッフル並べ替え段階でエラーが発生しました。既に実行中のエンジンが初期化されました。</entry>
    <entry key="MpiShufflerCancelled">他のワーカーの 1 つで、シャッフル並べ替え段階でエラーが発生しました。</entry>
    <entry key="MpiShufflerCannotRead">ローカル ファイルシステムからの読み取り時に、シャッフル並べ替え中にエラーが発生しました。</entry>
    <entry key="MpiShufflerCannotWrite">ローカル ファイルシステムへの書き込み時に、シャッフル並べ替え中にエラーが発生しました。</entry>
    <entry key="MpiShufflerCleanupError">シャッフル並べ替えエンジンのクリーンアップ中に内部エラーが発生しました。\n{0}</entry>
    <entry key="MpiShufflerInvalidCommand">シャッフル並べ替えエンジンに無効なコマンド ''{0}'' が渡されました。</entry>
    <entry key="MpiShufflerInvalidDestination">シャッフル並べ替えの出力先が無効です。出力先は、書き込み可能なフォルダーへのパスでなければなりません。</entry>
    <entry key="MpiShufflerInvalidSource">シャッフル並べ替えの入力が無効です。入力は、プールのサイズと同じ長さの、ファイル名のセル配列でなければなりません。</entry>
    <entry key="MpiShufflerInvalidTimeout">シャッフル並べ替えの確定タイムアウトが無効です。これは、正の整数を含むスカラーの double にする必要があります。</entry>
    <entry key="MpiShufflerNotRunning" context="error">シャッフル並べ替え段階でエラーが発生しました。データの送信前にエンジンが初期化されていません。</entry>
    <entry key="MpiShufflerUnknownError">シャッフル並べ替え段階で不明な内部エラーが検出されました。</entry>
    <entry key="ParallelHadoopMapReducerDisplayHeader" context="uistring">Hadoop クラスターでの mapreduce の並列実行。クラスター リソースが割り当てられるとすぐに評価が開始されます:</entry>
    <entry key="ParallelMapReducerDisplayHeader">並列プールでの mapreduce の並列実行:</entry>
    <entry key="ParallelOutputError">出力フォルダーに結果を書き込む際にエラーが発生しました。</entry>
    <entry key="SparkRequiresOutputFolder" context="error">To use Mapreduce with Spark, the ''OutputFolder'' parameter must specify a path that does not already exist.</entry>
    <entry key="SpmdEnabledRequired">指定された並列プールは mapreduce をサポートしていません。mapreduce には、'SpmdEnabled' プロパティを true に設定して起動したプールが必要です。</entry>
    <entry key="StartingSparkContext" context="uistring">クラスターで Spark ジョブを開始しています。これには数分かかることがありますが、同時にクラスター リソースが割り当てられます...\n\n</entry>
    <entry key="StartingSparkContextDone" context="uistring">Spark ジョブに接続しました。</entry>
    <entry key="UndefinedFunctionOnWorker">未定義関数のエラーが ''{0}'' のワーカーでスローされました。''{1}'' を含むファイルは、ワーカーで使用できないことがあります。次のコマンドを使用して、この並列プールに必要なファイルを指定してください: addAttachedFiles(pool, ...)。詳細は、parpool のドキュメンテーションを参照してください。</entry>
    <entry key="UndefinedFunctionOrHandleOnWorker">未定義関数のエラーがワーカーでスローされました。mapper 関数または reducer を含むファイルは、ワーカーで使用できないことがあります。次のコマンドを使用して、この並列プールに必要なファイルを指定してください: addAttachedFiles(pool, ...)。詳細は、parpool のドキュメンテーションを参照してください。</entry>
    <entry key="UnsupportedOutputSchemeForParallelMapReducer" context="error">Scheme ''{0}'' in location ''{1}'' is not supported. Map Reduce on a parallel pool currently supports writing only to locations of the form ''file:/path/to/location''.</entry>
  </message>
</rsccat>
