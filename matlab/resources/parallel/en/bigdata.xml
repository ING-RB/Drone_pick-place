<?xml version="1.0"?>
<!-- Copyright 2016-2023 The MathWorks, Inc. -->
<rsccat version="1.0" locale="en_US" product="parallel">
  <message>
      <entry key="ConfigurationInvalidDotIndexing" context="error">Dot indexing is not supported for {0}. Use ''{0}("propertyName")'' instead.</entry>
      <entry key="ConfigurationInvalidParenIndexing" context="error">Invalid index for {0}. Index must be a scalar string key.</entry>
      <entry key="ConfigurationInvalidValue" context="error">Invalid value for key ''{0}''. Allowed values are character vectors, string scalars, logical scalars, and numeric scalars.</entry>
      <entry key="ConfigurationManyEntriesHeader" context="uistring" note="Display of SparkProperties with hotlinked name of type (E.G 'SparkProperties with 16 entries')">  {0} with {1} entries</entry>
      <entry key="ConfigurationNoEntriesHeader" context="uistring" note="Display of SparkProperties with hotlinked name of type (E.G 'SparkProperties with no entries')">  {0} with no entries</entry>
      <entry key="ConfigurationOneEntryHeader" context="uistring" note="Display of SparkProperties with hotlinked name of type (E.G 'SparkProperties with 1 entry')">  {0} with 1 entry</entry>
      <entry key="HadoopPropertiesConstraint" context="error">Invalid value specified for property ''{0}''. Values must be of class ''parallel.cluster.HadoopProperties''.</entry>
      <entry key="MemoryTallOutOfMemory" context="error">Failed to send the in-memory data used to construct the tall array to process-based workers. Use the parallel environment PARPOOL("Threads") or MAPREDUCER(0) instead.</entry>
      <entry key="ParallelPoolName" context="uistring" note="Environment description used in position {1} of UnsupportedDatastore error and other messages">Parallel Pool</entry>
      <entry key="ParallelPoolWithProfileName" context="uistring" note="Environment description used in position {1} of UnsupportedDatastore error and other messages">Parallel Pool ''{0}''</entry>
      <entry key="SparkDriverCrash" context="error">The Spark Driver process has crashed, most likely because it ran out of memory. Consider increasing the 'spark.driver.memory' Spark property. See the documentation section {0}Specify Memory Properties{1} under parallel.cluster.Hadoop for more information.</entry>
      <entry key="SparkEnvironmentName" context="uistring" translate="false" note="Name of the third-party product Spark used in placeholders where we need to name the type of the environment">Spark</entry>
      <entry key="SparkNotFound" context="error">Unable to find Spark. Set the SPARK_HOME environment variable to a valid Spark installation folder or use the 'SparkInstallFolder' name-value parameter.</entry>
      <entry key="SparkJobStorageLocation" context="uistring">Database on local machine.</entry>
      <entry key="SparkPropertiesConstraint" context="error">Invalid value specified for property ''{0}''. Values must be of class ''parallel.cluster.SparkProperties''.</entry>
      <entry key="UnsupportedDatastore" context="error">Datastore of type ''{0}'' is not supported by the {1}. Use MAPREDUCER(0) to change the environment to the local MATLAB session.</entry>
      <entry key="UnsupportedCreateJobOnSpark" context="error">Job creation is not supported on clusters of type 'Spark'. Use Spark-enabled features TALL, MAPREDUCE or DATASTORE instead.</entry>
      <entry key="UnsupportedDefaultProfileOnSpark" context="error">Setting profile of type 'Spark' as default is not supported.</entry>
      <entry key="UnsupportedOnSpark" context="error">Not supported on clusters of type 'Spark'.</entry>
      <entry key="UnsupportedPoolOnSpark" context="error">Parallel pools are not supported on clusters of type 'Spark'. Use Spark-enabled features TALL, MAPREDUCE or DATASTORE instead.</entry>
  </message>
</rsccat>
