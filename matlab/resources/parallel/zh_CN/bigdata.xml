<?xml version="1.0" encoding="UTF-8"?>
<!--Copyright 2024 The MathWorks, Inc.-->

<rsccat xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.0" locale="zh_CN" product="parallel" xsi:noNamespaceSchemaLocation="../../resources/schema/msgcat.xsd">
  <message>
    <entry key="ConfigurationInvalidDotIndexing" context="error">{0} 不支持点索引。请改用 ''{0}("propertyName")''。</entry>
    <entry key="ConfigurationInvalidParenIndexing" context="error">{0} 的索引无效。索引必须为标量字符串键。</entry>
    <entry key="ConfigurationInvalidValue" context="error">键 ''{0}'' 的值无效。允许的值有字符向量、字符串标量、逻辑标量和数值标量。</entry>
    <entry key="ConfigurationManyEntriesHeader" context="uistring">  {0}(带 {1} 个条目)</entry>
    <entry key="ConfigurationNoEntriesHeader" context="uistring">  {0}(无条目)</entry>
    <entry key="ConfigurationOneEntryHeader" context="uistring">  {0}(带 1 个条目)</entry>
    <entry key="HadoopPropertiesConstraint" context="error">为属性 ''{0}'' 指定的值无效。值必须为 ''parallel.cluster.HadoopProperties'' 类。</entry>
    <entry key="MemoryTallOutOfMemory" context="error">Failed to send the in-memory data used to construct the tall array to process-based workers. Use the parallel environment PARPOOL("Threads") or MAPREDUCER(0) instead.</entry>
    <entry key="ParallelPoolName" context="uistring">并行池</entry>
    <entry key="ParallelPoolWithProfileName" context="uistring">并行池 ''{0}''</entry>
    <entry key="SparkDriverCrash" context="error">The Spark Driver process has crashed, most likely because it ran out of memory. Consider increasing the 'spark.driver.memory' Spark property. See the documentation section {0}Specify Memory Properties{1} under parallel.cluster.Hadoop for more information.</entry>
    <entry key="SparkNotFound" context="error">Unable to find Spark. Set the SPARK_HOME environment variable to a valid Spark installation folder or use the 'SparkInstallFolder' name-value parameter.</entry>
    <entry key="SparkJobStorageLocation" context="uistring">本地计算机上的数据库。</entry>
    <entry key="SparkPropertiesConstraint" context="error">为属性 ''{0}'' 指定的值无效。值必须为 ''parallel.cluster.SparkProperties'' 类。</entry>
    <entry key="UnsupportedDatastore" context="error">Datastore of type ''{0}'' is not supported by the {1}. Use MAPREDUCER(0) to change the environment to the local MATLAB session.</entry>
    <entry key="UnsupportedCreateJobOnSpark" context="error">类型为 'Spark' 的集群不支持创建作业。请改用 Spark 支持的功能 TALL、MAPREDUCE 或 DATASTORE。</entry>
    <entry key="UnsupportedDefaultProfileOnSpark" context="error">不支持将类型 'Spark' 的配置文件设置为默认值。</entry>
    <entry key="UnsupportedOnSpark" context="error">不支持类型为 'Spark' 的集群。</entry>
    <entry key="UnsupportedPoolOnSpark" context="error">类型为 'Spark' 的集群不支持并行池。请改用 Spark 支持的功能 TALL、MAPREDUCE 或 DATASTORE。</entry>
    <entry key="SparkEnvironmentName" context="uistring">Spark</entry>
  </message>
</rsccat>
