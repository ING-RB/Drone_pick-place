<?xml version="1.0" encoding="UTF-8"?>
<!--Copyright 2025 The MathWorks, Inc.-->

<rsccat xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.0" locale="ko_KR" product="gpucoder" xsi:noNamespaceSchemaLocation="../../resources/schema/msgcat.xsd">
  <message>
    <entry key="ZerosOrOnesUsedInsteadOfCoderNullCopy">변수의 값이 쓰기 작업으로 모두 채워질 것으로 예상되는 경우 coder.nullcopy()를 사용하여 불필요한 메모리 초기화를 방지합니다.</entry>
    <entry key="NoKernelFunPragma">자동 커널 생성을 가능하게 하려면 coder.gpu.kernelfun 프라그마를 함수 ''{0}''에 추가해 보십시오.</entry>
    <entry key="NoKernelPragmasFound">진입점 함수에서 coder.gpu.kernel 프라그마 또는 coder.gpu.kernelfun 프라그마를 찾을 수 없습니다. 최상위 진입점 함수에서 묵시적 coder.gpu.kernelfun 프라그마로 코드 생성을 수행합니다.</entry>
    <entry key="GpucoderSortWarning">성능을 향상시키려면 gpucoder.sort 함수를 사용해 보십시오.</entry>
    <entry key="DiagnosticReportGenerated">코드 생성 중 경고를 발견했습니다. 자세한 내용은 리포트의 '코드 인사이트' 탭과 '모든 메시지' 탭을 참조하십시오.</entry>
    <entry key="LargeLocalMemoryUsagePerThread">커널 ''{0}''에서 많은 양의 스레드 로컬 메모리를 사용하고 있습니다. 지역 변수를 줄여 MATLAB 루프를 다시 작성하면 커널 성능을 높일 수 있습니다.</entry>
    <entry key="ResampleConstInputWarning">성능을 향상시키려면 입력 신호 'x'를 제외한 모든 인수가 컴파일타임 상수여야 합니다.</entry>
    <entry key="MemoryLoweringGlobalVarWarning">GPU의 전역 변수 또는 영속 변수에 액세스하면 CPU와 GPU 간에 불필요한 데이터 복사가 발생할 수 있습니다. 가능하면 이러한 변수를 사용하지 마십시오.</entry>
    <entry key="MemoryLoweringAliasedVarWarning">GPU Coder는 별칭이 있는 변수의 경우 CPU와 GPU 간에 데이터 복사본을 효율적으로 삽입할 수 없습니다. 최상의 성능을 위해 GPU에서 핸들 객체와 동적으로 크기가 조정된 데이터에 액세스하지 마십시오.</entry>
    <entry key="MemoryLoweringTmpVarWarning">GPU Coder가 GPU에 직접 매핑할 수 없는 메모리 위치의 GPU 데이터를 저장하기 위해 임시 변수를 만들었습니다. 이러한 변수는 런타임 성능에 영향을 미칠 수 있습니다.</entry>
    <entry key="MemoryLoweringUnsupportedTypeError">GPU 액세스에 대해 지원되지 않는 유형을 가진 변수로 인해 GPU 코드 생성에 실패했습니다.</entry>
    <entry key="GpucoderRectifyStereoImagesWarning">stereoParams 인수에 대한 GPU 코드 생성이 최적화되지 않았습니다. 더 나은 코드 생성을 위해 사영 변환을 사용해 보십시오.</entry>
    <entry key="Ordfilt2InputVariableDimensions">가변 입력 크기에 대한 GPU 코드 생성이 최적화되지 않았습니다. CPU (C/C++) 코드를 대신 생성합니다. GPU 최적화된 코드를 생성하려면 상수 입력값을 사용해 보십시오.</entry>
    <entry key="Ordfilt2StackLimit">생성된 코드의 성능을 향상시키려면 GPU 구성의 StackLimitPerThread 속성을 Inf로 설정해 보십시오.</entry>
    <entry key="Ordfilt2DomainSize">GPU 코드 생성이 11×11보다 큰 도메인 크기에 대해 최적화되지 않았습니다.</entry>
    <entry key="MaxKernelPragmaDepthExceeded">최대 커널 시작 깊이를 초과하는 루프의 커널 프라그마는 허용되지 않을 수 있습니다.</entry>
    <entry key="ImadjustInputVardims">가변 입력 크기에 대한 GPU 코드 생성이 최적화되지 않았습니다. 최적화된 GPU 코드를 생성하려면 고정 크기 입력값을 사용해 보십시오.</entry>
    <entry key="Imreconstruct3DInput">GPU 코드 생성이 사용자 지정 연결 및 3차원 입력값에 대해 최적화되지 않았습니다.</entry>
    <entry key="ImwarpTransformationObjectNotConstant">최적화된 GPU 코드를 생성하려면 affine2d/projective2d 변환 객체가 상수여야 합니다.</entry>
    <entry key="ImwarpVariableDimensions">가변 입력 크기에 대한 GPU 코드 생성이 최적화되지 않았습니다. 최적화된 GPU 코드를 생성하려면 고정 크기 입력값을 사용해 보십시오.</entry>
    <entry key="PcdownsampleUnsupportedMethod">nonUniformGridSample 메서드에 대한 GPU 코드 생성이 최적화되지 않았습니다.</entry>
    <entry key="PcdownsampleUnsupportedRandomNumberGenerator">GPU 코드 생성은 'twister', 'combRecursive', 'philox' 난수 생성기를 지원합니다. 디폴트 난수 생성기 'philox'를 사용합니다.</entry>
    <entry key="InvalidMessageIdentifier">유효하지 않은 메시지 ID입니다.</entry>
    <entry key="InvalidWarningLevel">경고 수준은 0보다 크거나 같은 정수여야 합니다.</entry>
    <entry key="UseGpuInput">입력값 ''{0}''이(가) GPU에서 처음 사용되었으며 이로 인해 CPU에서 GPU로의 메모리 복사가 야기됩니다. 입력값을 GPU 유형 또는 gpuArray 객체로 지정하여 복사를 방지하십시오.</entry>
    <entry key="KernelDiagnosticsNotEnoughParallelism">커널에서 총 실행 시간 중 ''{0}''을(를) 사용하는데도 거의 스레드를 실행하지 못합니다. 이 실행 패턴은 각 스레드가 광범위한 계산을 수행하고 커널의 병렬 처리가 충분하지 않음을 나타냅니다.</entry>
    <entry key="MemoryDiagnosticsRepeatedMemoryCopyInsideLoop">생성된 코드에서 루프가 반복될 때마다 변수 ''{0}''이(가) CPU와 GPU 간에 복사됩니다. 이로 인해 GPU-CPU 동기화가 필요하고 애플리케이션 성능이 저하됩니다.</entry>
    <entry key="LongRunningLoopUnknownReason">루프가 CPU에서 실행되고 있으며 애플리케이션 시간의 ''{0}''을(를) 차지합니다. 루프를 GPU로 분담하여 성능을 개선하려면 루프를 병렬 처리해 보십시오.</entry>
    <entry key="LongCPULoopHasLargeMemcpy">루프가 CPU에서 실행되고 있으며, 이로 인해 루프에서 GPU-CPU 동기화가 강제로 발생합니다. 루프를 병렬 처리하여 GPU-CPU 동기화를 제거할 수 있습니다.</entry>
    <entry key="LongRunningLoopLargeIteration">루프가 ''{0}''회 반복되며 이는 총 시간의 상당한 비중을 차지합니다. 루프를 병렬 처리하여 성능을 개선할 수 있습니다. </entry>
    <entry key="KernelLaunchOverheadLargeInLoop">루프로 인해 오버헤드가 높고 계산 성능이 낮은 중요하지 않은 커널이 상당수 실행됩니다. 이 상황은 자식 루프가 중첩 루프 내에서 병렬화된 경우 발생합니다. 부모 루프를 병렬화하여 성능을 개선할 수 있습니다.</entry>
    <entry key="DLNetworkSlow">딥러닝 신경망이 애플리케이션 런타임 중 ''{0}''을(를) 차지합니다. 자세한 내용은 딥러닝 대시보드를 참조하십시오.</entry>
    <entry key="DLNetworkEffcy">딥러닝 신경망이 효율적으로 실행 중이며 제안이 발견되지 않았습니다.</entry>
    <entry key="DLLayerLowEffcyLowUt">계층 ''{0}''이(가) 신경망 실행 시간 중 ''{1}''을(를) 차지하며 GPU 사용률이 낮습니다. 더 많은 연산을 GPU로 옮겨 보십시오.</entry>
    <entry key="DLLayerLowEffcyHighUt">계층 ''{0}''에서 신경망 실행 시간 중 ''{1}''을(를) 사용합니다. 계층이 GPU를 충분히 활용하지만 GPU 연산이 병목 상태입니다.</entry>
  </message>
</rsccat>
